\chapter{Shannonova kapacita}

Představme si zašuměný komunikační kanál, kterým posíláme zprávy, které jsou složeny ze symbolů (písmen) nějaké konečné abecedy. Vlivem šumu mohou být některé symboly špatně interpretovány a naším cílem je vybrat co největší počet slov délky $k$ tak, aby žádná dvě slova nebyla vlivem šumu zaměnitelná.

Problém si formalizujeme v řeči teorie grafů. Mějme neorientovaný graf $G = (V, E)$, kde množina vrcholů představuje symboly z konečné abecedy a dva vrcholy $x, y$ jsou spojeny hranou, pokud vrchol $x$ může být vlivem šumu zaměněn za $y$.

Maximální počet nezaměnitelných zpráv délky $1$ je roven $\alpha(G)$, kde $\alpha(G)$ značí velikost největší nezávislé množiny v grafu $G$. Pro popis delších zpráv definujeme \textbf{silný součin} $G \cdot H$ grafů $G$ a $H$ následovně:
$$
    V(G \cdot H) = V(G) \times V(H),
$$
\begin{equation*}
    \begin{split}
    E(G \cdot H) = &\left\{ (i,u)(j,v) \mid ij \in E(G) \wedge uv \in E(H) \right\} \cup \\
                   &\left\{ (i,u)(j,v) \mid ij \in E(G) \wedge u = v \right\} \cup \\
                   &\left\{ (i,u)(j,v) \mid i = j \wedge uv \in E(H) \right\}.
    \end{split}
\end{equation*}

\begin{pr}
Pro graf $P_4 = a-b-c-d-e$ je silný součin $P_4 \cdot P_4$ zobrazen na obrázku~\ref{fig:strong_product_P4_P4}. Z obrázku je hezky vidět, že např. zpráva $cd$ (na obrázku červeně) může být zaměněna s $bc$, $bd$, $be$, $cc$, $ce$, $dc$, $dd$ a $de$ (na obrázku oranžově). Podobně pro další zprávy.
\end{pr}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\textwidth]{img/strong_product_P4_P4.png}   
    \caption{$P_4 \cdot P_4$}
    \label{fig:strong_product_P4_P4}
\end{figure}

Pro jednoduchost budeme silný součin $k$ kopií grafu $G$ značit $G^k$. Tedy $\alpha(G^k)$ je maximální počet nezaměnitelných zpráv délky $k$. \textbf{Shannonova kapacita} grafu $G$ je definována jako
$$
    \Theta(G) = \sup \left\{ \alpha(G^k)^{1/k} \mid k = 1, 2, \dots \right\}.
$$

Neví se, zda pro libovolný graf $G$ existuje vůběc nějaký algoritmus, kterým bychom určili hodnotu $\Theta(G)$. Přesto je alespoň něco známo. Pro perfektní grafy Claude E. Shannon ukázal, že $\Theta(G) = \alpha(G)$. To také znamená, že pro perfektní grafy lze $\Theta(G)$ určit v polynomiálním čase. Dalším kdo se problémem zabýval byl László Lovász, který velmi hezkým způsobem ukázal, že kružnice délky $5$ má kapacitu $\sqrt{5}$. Na Lovászův postup se dále podíváme, protože vede k obecnému hornímu odhadu na $\Theta(G)$.

\section{$\Theta(C_5) = \sqrt{5}$}

\textbf{Tenzorový součin} vektorů $\mathbf{u} = \left(u_1, \dots, u_n \right)$ a $\mathbf{v} = \left(v_1, \dots, v_m \right)$ je
$$
    \mathbf{u} \circ \mathbf{v} = \left( u_1 v_1, \dots, u_1 v_m, u_2 v_1, \dots, u_n v_m \right).
$$

Užitečné bude následující pozorování, které dává do souvisloti skalární a tenzorový součin.

\begin{pz}
    Nechť $\mathbf{x}, \mathbf{u}$ jsou vektory délky $n$ a $\mathbf{y}, \mathbf{v}$ jsou vektory délky $m$. Potom platí
    \begin{equation}
        \left( x \circ y \right)^T \left( u \circ v \right) = \left( x^T u \right) \left( y^T v \right).
        \label{eq:tensor_scalar_product}
    \end{equation}
\end{pz}

\begin{proof}
    Levá strana:
    \begin{equation*}
        \begin{split}
        & \left(x_1 y_1, x_1 y_2, \dots, x_1 y_m, \dots, x_n y_m \right)^T \left( u_1 v_1, u_1 v_2, \dots, u_1 v_m, \dots, u_n v_m \right) = \\
        & x_1 y_1 u_1 v_1 + x_1 y_2 u_1 v_2 + \dots + x_1 y_m u_1 v_m + \dots + x_m y_m u_n v_m
        \end{split}
    \end{equation*}
    Pravá strana:
    \begin{equation*}
        \begin{split}
            & \left( x_1 u_1 + \dots + x_n u_n \right) \cdot \left( y_1 v_1 + \dots + y_n v_m \right) = \\
            & x_1 y_1 u_1 v_1 + x_1 y_2 u_1 v_2 + \dots + x_1 y_m u_1 v_m + \dots + x_m y_m u_n v_m
        \end{split}
    \end{equation*}
\end{proof}

Mějme graf $G = (V,E)$, kde $V = \left\{ 1, \dots, n \right\}$. Systém $\left( \textbf{v}_1, \dots, \textbf{v}_n \right)$ jednotkových vektorů v Euklidovském prostoru takový, že
$$
    \forall ij \notin E \implies \textbf{v}_i \perp \textbf{v}_j
$$
nazýváme \textbf{ortonormální reprezentace} grafu $G$. Poznamenejme, že každý graf má nějakou ortonormální reprezentaci, např. $1 \mapsto \mathbf{e}_1, \dots, n \mapsto \mathbf{e}_n$.

\begin{lm}
    Nechť $\left( \mathbf{u}_1, \dots, \mathbf{u}_n \right)$ je ortonormální reprezentace grafu $G$ a $\left( \mathbf{v}_1, \dots, \mathbf{v}_m \right)$ je ortonormální reprezentace grafu $H$. Potom $\mathbf{u}_i \circ \mathbf{v}_j$ je ortonormální reprezentace grafu $G \cdot H$.
\end{lm}

\begin{proof}
    Použijeme vztah \ref{eq:tensor_scalar_product}. $\left( u_i \circ v_j \right)^T \left( u_k \circ v_l \right) = \left( u_i^T u_k \right) \left( v_j^T v_l \right) = 0 \iff ik \notin E(G) \vee jl \notin E(H)$.
\end{proof}

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\textwidth]{img/shannon_lemma.png}   
    \caption{Ortornomální reprezentace $G \cdot H$.}
    \label{fig:orthonormal_repr_GH}
\end{figure}

\textbf{Hodnotu} ortonormální reprezentace $\left(u_+, \dots, u_n \right)$ definujeme jako:
$$
    \min_c \max_{i = 1, \dots, n} \frac{1}{\left( c^T u_i \right)^2}.
$$
Vektoru $c$, pro který nastává minimum říkáme \textbf{\uv{rukojeť}} (anglicky handle) dané ortonormální reprezentace.

Dále definujeme funkci $\vartheta(G)$ jako minimální hodnotu přes všechny ortonormální reprezentace grafu $G$. Ortonormální reprezentaci, pro kterou nastává minumum nazýváme \textbf{optimální}.

Funkci $\vartheta(G)$ se říká \textbf{Lovászova theta funkce} a ona je právě již zmíněným horním odhadem na $\Theta(G)$. Podívejme se na některé její vlastnosti.

\begin{lm}
    $\vartheta(G \cdot H) \leq \vartheta(G) \vartheta(H)$
\end{lm}

\begin{proof}
    Nechť $\left( u_1, \dots, u_n \right)$ je optimální ortonormální reprezentace grafu $G$ s \uv{rukojetí} $c$ a $\left( v_1, \dots, v_m \right)$ je optimální ortonormální reprezentace grafu $H$ s \uv{rukojetí} $d$. Pak $c \circ d$ je jednotkový vektor a platí:
    $$
        \vartheta(G \cdot H) \leq \max_{i,j} \frac{1}{\left( \left( c \circ d \right)^T \left( u_i \circ v_j \right) \right)^2} = \max_i \frac{1}{\left( c^T u_i \right)^2} \cdot \max_j \frac{1}{\left( d^T v_j \right)^2} = \vartheta(G)\vartheta(H).
    $$
\end{proof}

\begin{lm}
    $\alpha(G) \leq \vartheta(G)$
\end{lm}

\begin{proof}
    TODO (máš to někde na papíře)
\end{proof}

\begin{lm}
    $\Theta(G) \leq \vartheta(G)$
\end{lm}

\begin{proof}
    TODO (máš to někde na papíře)
\end{proof}

\begin{vt}
    $\Theta(C_5) = \sqrt{5}$
\end{vt}

\begin{proof}
    TODO (obě nerovnosti, obrázek, spherical cosine theorem)
\end{proof}


\section{Další vlastnosti $\vartheta(G)$}
vztah k barvení ($\overline{G}$), ...


\section{Semidefinitní program pro $\vartheta(G)$}

formulace semidefinitních programů (jsou dva ekvivalentní -- to asi nenaimplementuješ, je to docela pekelný, nic nespočítáš), subgradientní aproximační metoda (zkusit naimplementovat???)
